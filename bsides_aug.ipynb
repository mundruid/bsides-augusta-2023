{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "import ipaddress\n",
    "\n",
    "from scapy.all import PcapReader, IP, TCP, UDP, ICMP\n",
    "from scipy.stats import ttest_ind, kstest, norm, skew, kurtosis, zscore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skimpy import skim\n",
    "from summarytools import dfSummary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap_reader_mirai = PcapReader(\"data/mirai.pcap\")\n",
    "pcap_reader_benign = PcapReader(\"data/benign.pcapng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pcap_reader_benign)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "- convert data to streams\n",
    "- collect some numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcap_to_dataframe(pcap_reader: PcapReader) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        pcap_reader (PcapReader): packet capture read using scapy\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with pcap data\n",
    "    \"\"\"\n",
    "    # Create an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Iterate through the packets in the pcap file\n",
    "    for packet in pcap_reader:\n",
    "        # Get the source and destination IP addresses\n",
    "        if packet.haslayer(IP):\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "            protocol = packet[IP].proto\n",
    "        else:\n",
    "            src_ip = None\n",
    "            dst_ip = None\n",
    "            protocol = None\n",
    "\n",
    "        # Get the source and destination ports and payload\n",
    "        if packet.haslayer(TCP):\n",
    "            src_port = packet[TCP].sport\n",
    "            dst_port = packet[TCP].dport\n",
    "            payload = str(packet[TCP].payload)\n",
    "            packet_len = len(packet[TCP])\n",
    "        elif packet.haslayer(UDP):\n",
    "            src_port = packet[UDP].sport\n",
    "            dst_port = packet[UDP].dport\n",
    "            payload = str(packet[UDP].payload)\n",
    "            packet_len = len(packet[UDP])\n",
    "        elif packet.haslayer(ICMP):\n",
    "            payload = str(packet[ICMP].payload)\n",
    "            packet_len = len(packet[ICMP])\n",
    "            src_port = None\n",
    "            dst_port = None\n",
    "        else:\n",
    "            src_port = None\n",
    "            dst_port = None\n",
    "            payload = str(packet.payload)\n",
    "            packet_len = len(packet)\n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append(\n",
    "            [\n",
    "                packet.time,\n",
    "                src_ip,\n",
    "                dst_ip,\n",
    "                src_port,\n",
    "                dst_port,\n",
    "                payload,\n",
    "                packet_len,\n",
    "                protocol,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Convert the list to a pandas dataframe\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"Timestamp\",\n",
    "            \"Source IP\",\n",
    "            \"Destination IP\",\n",
    "            \"Source Port\",\n",
    "            \"Destination Port\",\n",
    "            \"Payload\",\n",
    "            \"Packet Length\",\n",
    "            \"Protocol\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirai_df = pcap_to_dataframe(pcap_reader_mirai)\n",
    "# benign_df = pcap_to_dataframe(pcap_reader_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirai_df.to_pickle(\"../data/bsides_aug/mirai.pkl\")\n",
    "# benign_df.to_pickle(\"../data/bsides_aug/benign.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_df = pd.read_pickle(\"data/mirai.pkl\")\n",
    "benign_df = pd.read_pickle(\"data/benign.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use pandas AI to ask questions from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_streams(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create an empty list to store stream data as separate dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Group packets by src/dst IP and src/dst port\n",
    "    grouped = df.groupby(\n",
    "        [\"Source IP\", \"Destination IP\", \"Source Port\", \"Destination Port\", \"Protocol\"]\n",
    "    )\n",
    "\n",
    "    # Iterate through each group to extract stream data\n",
    "    for name, group in grouped:\n",
    "        # Get source/destination IP, port, and protocol\n",
    "        src_ip, dst_ip, src_port, dst_port, proto = name\n",
    "\n",
    "        # Get number of packets, total length, and duration of the stream\n",
    "        num_packets = len(group)\n",
    "        total_length = group[\"Packet Length\"].sum()\n",
    "        start_time = group[\"Timestamp\"].min()\n",
    "        end_time = group[\"Timestamp\"].max()\n",
    "        duration = float(end_time - start_time)\n",
    "\n",
    "        # Create a new dataframe with the stream data\n",
    "        stream_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Source IP\": [src_ip],\n",
    "                \"Destination IP\": [dst_ip],\n",
    "                \"Source Port\": [src_port],\n",
    "                \"Destination Port\": [dst_port],\n",
    "                \"Protocol\": [proto],\n",
    "                \"Number of Packets\": [num_packets],\n",
    "                \"Total Length\": [total_length],\n",
    "                \"Duration\": [duration],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add the new dataframe to the list\n",
    "        dfs.append(stream_df)\n",
    "\n",
    "    # Concatenate all the dataframes in the list into one dataframe\n",
    "    stream_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Return the new dataframe with stream data\n",
    "    return stream_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_stream_df = extract_streams(mirai_df)\n",
    "benign_stream_df = extract_streams(benign_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Exploratory Data Analysis approaches the dataset as a black box that we need to visualize and analyze statistically with the following goals:\n",
    "- get insights about our data\n",
    "- test hypotheses\n",
    "- decide on models and further processing, such as feature engineering.\n",
    "\n",
    "EDA can be performed for benign and malicious data. Here we are looking at EDA only for malicious data, however the same functions can be applied to benign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics & data\n",
    "\n",
    "- Describe columns and data types\n",
    "- Descriptive statistics\n",
    "  -  count, \n",
    "  -  mean, \n",
    "  -  standard deviation, \n",
    "  -  minimum, \n",
    "  -  25th percentile, \n",
    "  -  median (50th percentile), \n",
    "  -  75th percentile, and \n",
    "  -  maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe, summarize etc.\n",
    "mirai_stream_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_stream_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "mirai_stream_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix for numerical values in dataframe\n",
    "mirai_stream_df.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "- Is the difference between two groups or variables statistically significant?\n",
    "- Use t-test to compare means of two groups\n",
    "  - assumes that data follows normal distribution\n",
    "- Types of variables\n",
    "  - dependent: the effect of a phenomenon. For example, how does number of HTTP requests mean that a network is compromised?\n",
    "  - independent: the cause. The number of HTTP requests affects whether a network is compromised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_testing(df, col1, col2):\n",
    "    group1 = df[col1]\n",
    "    group2 = df[col2]\n",
    "    pvalue = ttest_ind(group1, group2)[1]\n",
    "    if pvalue < 0.05:\n",
    "        return \"The difference between {} and {} is statistically significant (p < 0.05)\".format(\n",
    "            col1, col2\n",
    "        )\n",
    "    else:\n",
    "        return \"The difference between {} and {} is not statistically significant (p >= 0.05)\".format(\n",
    "            col1, col2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_testing(mirai_stream_df, \"Number of Packets\", \"Total Length\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "\n",
    "- Models relationship between a dependent variable and one or more independent variables\n",
    "- Linear regression\n",
    "  - fit data in line\n",
    "  - calculate coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_analysis(df, x_cols, y_col):\n",
    "    X = df[x_cols].values.reshape(-1, len(x_cols))\n",
    "    y = df[y_col].values.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    r_sq = model.score(X, y)\n",
    "    coef = model.coef_\n",
    "    return {\"R-squared\": r_sq, \"Coefficients\": coef}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_analysis(mirai_stream_df, [\"Number of Packets\", \"Duration\"], \"Total Length\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov test\n",
    "\n",
    "- compare two sample distributions\n",
    "- useful for fitting to a distribution\n",
    "- test if two samples from a population:\n",
    "  - came from a distribution\n",
    "  - belong to the same distribution\n",
    "- Uses metric `D`\n",
    "  - max absolute difference between empirical distribution function of the samples and cumulative distribution of the reference distribution\n",
    "- Null hypothesis: \n",
    "  - samples came from the reference distribution\n",
    "  - samples came from the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_smirnov_test(df, column):\n",
    "    sample = df[column].values\n",
    "    _, pvalue = kstest(sample, norm.cdf, args=(sample.mean(), sample.std()))\n",
    "    if pvalue < 0.05:\n",
    "        return \"The distribution of {} is significantly different from a normal distribution (p < 0.05)\".format(\n",
    "            column\n",
    "        )\n",
    "    else:\n",
    "        return \"The distribution of {} is not significantly different from a normal distribution (p >= 0.05)\".format(\n",
    "            column\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolmogorov_smirnov_test(mirai_stream_df, \"Total Length\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness and Kyrtosis\n",
    "\n",
    "- information about the shape of the distribution\n",
    "- Skewness: measure the degree of asymmetry\n",
    "  - symmetric: equally balanced around its mean\n",
    "  - asymmetric: not equally balanced\n",
    "  - positive skewness: distribution longer on the right side\n",
    "  - negative skewness: longer on the left\n",
    "  - 0: completely symmetric\n",
    "- Kurtosis: peakedness of distribution\n",
    "  - high: sharp peak, long tails\n",
    "  - low: flat peak, short tails\n",
    "  - ex. normal distribution has kurtosis 3, mesokurtic\n",
    "    - `> 3` leptokurtic\n",
    "    - `< 3` platykurtic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_kurtosis(df):\n",
    "    result = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        result[col + \"_skewness\"] = skew(df[col])\n",
    "        result[col + \"_kurtosis\"] = kurtosis(df[col])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness_kurtosis(mirai_stream_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "- observation that significantly differs from others in a dataset\n",
    "- Causes\n",
    "  - measurement errors\n",
    "  - extreme rare values\n",
    "- significant impact in statistical analysis\n",
    "- measurements\n",
    "  - z-score: `(x - mean) / std_dev`\n",
    "  - IQR method: this method identifies outliers as observations that are below `Q1 - 1.5IQR` or above `Q3 + 1.5IQR`, where Q1 and Q3 are the first and third quartiles, and IQR is the interquartile range (the difference between Q3 and Q1).\n",
    "  - visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    zscores = np.abs(zscore(df[column]))\n",
    "    return df[zscores > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = detect_outliers_zscore(mirai_stream_df, \"Total Length\", threshold=3)\n",
    "print(outliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ip address to numeric values\n",
    "def ip_to_numeric(ip):\n",
    "    ip_obj = ipaddress.ip_interface(ip)\n",
    "    return int(ip_obj.network.network_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IPs to numeric mirai data\n",
    "mirai_stream_df[\"Source IP Numeric\"] = mirai_stream_df[\"Source IP\"].apply(ip_to_numeric)\n",
    "mirai_stream_df[\"Destination IP Numeric\"] = mirai_stream_df[\"Destination IP\"].apply(\n",
    "    ip_to_numeric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IPs to numeric benign data\n",
    "benign_stream_df[\"Source IP Numeric\"] = benign_stream_df[\"Source IP\"].apply(\n",
    "    ip_to_numeric\n",
    ")\n",
    "benign_stream_df[\"Destination IP Numeric\"] = benign_stream_df[\"Destination IP\"].apply(\n",
    "    ip_to_numeric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of non numeric columns for IPs\n",
    "mirai_stream_df_numeric = mirai_stream_df.drop(columns=[\"Source IP\", \"Destination IP\"])\n",
    "benign_stream_df_numeric = benign_stream_df.drop(\n",
    "    columns=[\"Source IP\", \"Destination IP\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration from object to float\n",
    "mirai_stream_df[\"Duration\"] = mirai_stream_df_numeric[\"Duration\"].astype(float)\n",
    "benign_stream_df[\"Duration\"] = benign_stream_df_numeric[\"Duration\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all data types are numeric now\n",
    "mirai_stream_df_numeric.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(mirai_stream_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(benign_stream_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(mirai_stream_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(benign_stream_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(mirai_stream_df_numeric)\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(benign_stream_df_numeric)\n",
    "my_report.show_html()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling\n",
    "We label and concatenate benign and malicious before one-hot because there are different ports in each dataset and concatenating the two after one hot will not work with different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels, 0 for benign, 1 for malicious\n",
    "mirai_stream_df_numeric[\"Labels\"] = 1\n",
    "benign_stream_df_numeric[\"Labels\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "data_df = pd.concat([mirai_stream_df_numeric, benign_stream_df_numeric], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering (cont.) categorical \n",
    "## One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, feature):\n",
    "    feature_dummies = pd.get_dummies(df[feature], prefix=feature)\n",
    "    return pd.concat([df, feature_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = one_hot_encode(data_df, \"Source Port\")\n",
    "data_df = one_hot_encode(data_df, \"Destination Port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use skllm or embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "- models\n",
    "  - xgboost\n",
    "  - NN\n",
    "  - k-NN\n",
    "  - Random Forest\n",
    "- k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the data. TODO: is this needed\n",
    "from sklearn.utils import shuffle\n",
    "data_df = shuffle(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after feature engineering, drop all the columns that are unnecessary\n",
    "data_df = data_df.drop([\"Source Port\", \"Destination Port\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the features and labels in separate dataframes\n",
    "X = data_df.drop(\"Labels\", axis=1)\n",
    "y = data_df[\"Labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to array\n",
    "data_array = data_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 1\n",
    "for train, test in kfold.split(data_array):\n",
    "    print(f\"Model {model}\")\n",
    "    print(f\"train {train}, test: {test}\")\n",
    "    model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model, X, y):\n",
    "    accuracy_scores = []\n",
    "    for train, test in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # evaluate model accuracy\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        \n",
    "    return accuracy_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average accuracy score across all folds\n",
    "accuracy_scores = train_evaluate_model(knn_model, X, y)\n",
    "average_accuracy = sum(accuracy_scores) / k\n",
    "print(\"Average accuracy k-nn:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average accuracy score across all folds\n",
    "accuracy_scores = train_evaluate_model(rf_model, X, y)\n",
    "average_accuracy = sum(accuracy_scores) / k\n",
    "print(\"Average accuracy random forest:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average accuracy score across all folds\n",
    "accuracy_scores = train_evaluate_model(xgb_model, X, y)\n",
    "average_accuracy = sum(accuracy_scores) / k\n",
    "print(\"Average accuracy XGBoost:\", average_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
